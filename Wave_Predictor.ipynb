{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wave Predictor.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liady/ssp19ai/blob/master/Wave_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRP_VW7BKUyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Inspired by example from\n",
        "https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent\n",
        "Uses the TensorFlow backend\n",
        "The basic idea is to detect anomalies in a time-series.\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from numpy import arange, sin, pi, random\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Global hyper-parameters\n",
        "sequence_length = 100\n",
        "random_data_dup = 10  # each sample randomly duplicated between 0 and 9 times, see dropin function\n",
        "epochs = 1\n",
        "batch_size = 50\n",
        "\n",
        "\n",
        "def dropin(X, y):\n",
        "    \"\"\" The name suggests the inverse of dropout, i.e. adding more samples. See Data Augmentation section at\n",
        "    http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/\n",
        "    :param X: Each row is a training sequence\n",
        "    :param y: Tne target we train and will later predict\n",
        "    :return: new augmented X, y\n",
        "    \"\"\"\n",
        "    print(\"X shape:\", X.shape)\n",
        "    print(\"y shape:\", y.shape)\n",
        "    X_hat = []\n",
        "    y_hat = []\n",
        "    for i in range(0, len(X)):\n",
        "        for j in range(0, np.random.random_integers(0, random_data_dup)):\n",
        "            X_hat.append(X[i, :])\n",
        "            y_hat.append(y[i])\n",
        "    return np.asarray(X_hat), np.asarray(y_hat)\n",
        "\n",
        "\n",
        "def gen_wave():\n",
        "    \"\"\" Generate a synthetic wave by adding up a few sine waves and some noise\n",
        "    :return: the final wave\n",
        "    \"\"\"\n",
        "    t = np.arange(0.0, 10.0, 0.01)\n",
        "    wave1 = sin(2 * 2 * pi * t)\n",
        "    noise = random.normal(0, 0.1, len(t))\n",
        "    wave1 = wave1 + noise\n",
        "    print(\"wave1\", len(wave1))\n",
        "    wave2 = sin(2 * pi * t)\n",
        "    print(\"wave2\", len(wave2))\n",
        "    t_rider = arange(0.0, 0.5, 0.01)\n",
        "    wave3 = sin(10 * pi * t_rider)\n",
        "    print(\"wave3\", len(wave3))\n",
        "    insert = round(0.8 * len(t))\n",
        "    wave1[int(insert):int(insert) + 50] = wave1[int(insert):int(insert) + 50] + wave3\n",
        "    return wave1 + wave2\n",
        "\n",
        "\n",
        "def z_norm(result):\n",
        "    result_mean = result.mean()\n",
        "    result_std = result.std()\n",
        "    result -= result_mean\n",
        "    result /= result_std\n",
        "    return result, result_mean\n",
        "\n",
        "\n",
        "def get_split_prep_data(train_start, train_end,\n",
        "                          test_start, test_end):\n",
        "    data = gen_wave()\n",
        "    print(\"Length of Data\", len(data))\n",
        "\n",
        "    # train data\n",
        "    print \"Creating train data...\"\n",
        "\n",
        "    result = []\n",
        "    for index in range(train_start, train_end - sequence_length):\n",
        "        result.append(data[index: index + sequence_length])\n",
        "    result = np.array(result)  # shape (samples, sequence_length)\n",
        "    result, result_mean = z_norm(result)\n",
        "\n",
        "    print \"Mean of train data : \", result_mean\n",
        "    print \"Train data shape  : \", result.shape\n",
        "\n",
        "    train = result[train_start:train_end, :]\n",
        "    np.random.shuffle(train)  # shuffles in-place\n",
        "    X_train = train[:, :-1]\n",
        "    y_train = train[:, -1]\n",
        "    X_train, y_train = dropin(X_train, y_train)\n",
        "\n",
        "    # test data\n",
        "    print \"Creating test data...\"\n",
        "\n",
        "    result = []\n",
        "    for index in range(test_start, test_end - sequence_length):\n",
        "        result.append(data[index: index + sequence_length])\n",
        "    result = np.array(result)  # shape (samples, sequence_length)\n",
        "    result, result_mean = z_norm(result)\n",
        "\n",
        "    print \"Mean of test data : \", result_mean\n",
        "    print \"Test data shape  : \", result.shape\n",
        "\n",
        "    X_test = result[:, :-1]\n",
        "    y_test = result[:, -1]\n",
        "\n",
        "    print(\"Shape X_train\", np.shape(X_train))\n",
        "    print(\"Shape X_test\", np.shape(X_test))\n",
        "\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    layers = {'input': 1, 'hidden1': 64, 'hidden2': 256, 'hidden3': 100, 'output': 1}\n",
        "\n",
        "    model.add(LSTM(\n",
        "            input_length=sequence_length - 1,\n",
        "            input_dim=layers['input'],\n",
        "            output_dim=layers['hidden1'],\n",
        "            return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(\n",
        "            layers['hidden2'],\n",
        "            return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(\n",
        "            layers['hidden3'],\n",
        "            return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(\n",
        "            output_dim=layers['output']))\n",
        "    model.add(Activation(\"linear\"))\n",
        "\n",
        "    start = time.time()\n",
        "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
        "    print \"Compilation Time : \", time.time() - start\n",
        "    return model\n",
        "\n",
        "\n",
        "def run_network(model=None, data=None):\n",
        "    global_start_time = time.time()\n",
        "\n",
        "    if data is None:\n",
        "        print 'Loading data... '\n",
        "        # train on first 700 samples and test on next 300 samples (has anomaly)\n",
        "        X_train, y_train, X_test, y_test = get_split_prep_data(0, 700, 500, 1000)\n",
        "    else:\n",
        "        X_train, y_train, X_test, y_test = data\n",
        "\n",
        "    print '\\nData Loaded. Compiling...\\n'\n",
        "\n",
        "    if model is None:\n",
        "        model = build_model()\n",
        "\n",
        "    try:\n",
        "        print(\"Training...\")\n",
        "        model.fit(\n",
        "                X_train, y_train,\n",
        "                batch_size=batch_size, nb_epoch=epochs, validation_split=0.05)\n",
        "        print(\"Predicting...\")\n",
        "        predicted = model.predict(X_test)\n",
        "        print(\"Reshaping predicted\")\n",
        "        predicted = np.reshape(predicted, (predicted.size,))\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"prediction exception\")\n",
        "        print 'Training duration (s) : ', time.time() - global_start_time\n",
        "        return model, y_test, 0\n",
        "\n",
        "    try:\n",
        "        plt.figure(1)\n",
        "        plt.subplot(311)\n",
        "        plt.title(\"Actual Test Signal w/Anomalies\")\n",
        "        plt.plot(y_test[:len(y_test)], 'b')\n",
        "        plt.subplot(312)\n",
        "        plt.title(\"Predicted Signal\")\n",
        "        plt.plot(predicted[:len(y_test)], 'g')\n",
        "        plt.subplot(313)\n",
        "        plt.title(\"Squared Error\")\n",
        "        mse = ((y_test - predicted) ** 2)\n",
        "        plt.plot(mse, 'r')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(\"plotting exception\")\n",
        "        print str(e)\n",
        "    print 'Training duration (s) : ', time.time() - global_start_time\n",
        "\n",
        "    return model, y_test, predicted\n",
        "\n",
        "\n",
        "run_network()\n",
        "print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}