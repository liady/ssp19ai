{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Excercise 4 - Fashion MNIST CNN Classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liady/ssp19ai/blob/master/Excercise_4_Fashion_MNIST_CNN_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2ArjSbvNIlA"
      },
      "source": [
        "# ISU - Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e048l5KPRvC"
      },
      "source": [
        "<img src=\"https://i.ibb.co/KV784Nc/SSP19.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m3JvqB5NVH4"
      },
      "source": [
        "# Convolutional Neural Network Classifier - Fashion MNIST\n",
        "<img src=\"https://github.com/margaretmz/deep-learning/blob/master/images/modern%20dl_fash-mnist_keras.png?raw=1\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"450\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAJuYw3BQG8f"
      },
      "source": [
        "###Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gK_BOWyQK2r"
      },
      "source": [
        "Let's make sure we have the latest version of [TensorFlow](https://www.tensorflow.org/tutorials) Installed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo0msBDdpxQZ"
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k_B-B7eQa0L"
      },
      "source": [
        "Let's also make sure to import all the libraries that we need in order to run the excercise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8vETwvPakr8"
      },
      "source": [
        "# install helper utilities\n",
        "!git clone https://github.com/liady/ssp19ai_utils.git\n",
        "!git -C ssp19ai_utils pull\n",
        "import ssp19ai_utils.utils as utils\n",
        "import importlib\n",
        "importlib.reload(utils)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCN9gxfpQYzL"
      },
      "source": [
        "%matplotlib inline\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf # The framework to run our models\n",
        "from tensorflow import keras # High order layers, models, etc\n",
        "from keras.utils import to_categorical # Utilities\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version is \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbCigZtNZZgl"
      },
      "source": [
        "## Download the fashion_mnist data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d44TznbgZZgm"
      },
      "source": [
        "# Load the fashion-mnist pre-shuffled train data and test data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWORMSC8FDR4"
      },
      "source": [
        "## Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFe4wHGRFKle"
      },
      "source": [
        "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Print the number of training and test datasets\n",
        "print(x_train.shape[0], 'train set')\n",
        "print(x_test.shape[0], 'test set')\n",
        "\n",
        "# Define the text labels\n",
        "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
        "                        \"Trouser\",      # index 1\n",
        "                        \"Pullover\",     # index 2 \n",
        "                        \"Dress\",        # index 3 \n",
        "                        \"Coat\",         # index 4\n",
        "                        \"Sandal\",       # index 5\n",
        "                        \"Shirt\",        # index 6 \n",
        "                        \"Sneaker\",      # index 7 \n",
        "                        \"Bag\",          # index 8 \n",
        "                        \"Ankle boot\"]   # index 9\n",
        "\n",
        "# Image index, you can pick any number between 0 and 59,999\n",
        "img_index = 5\n",
        "# y_train contains the lables, ranging from 0 to 9\n",
        "label_index = y_train[img_index]\n",
        "# Print the label, for example 2 Pullover\n",
        "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
        "# # Show one of the images from the training dataset\n",
        "plt.imshow(x_train[img_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-Ee6LHZZgt"
      },
      "source": [
        "## Data normalization\n",
        "Normalize the data dimensions so that they are of approximately the same scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNh5NIckZZgu"
      },
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# Reshape (why?)\n",
        "x_train = x_train.reshape(-1,28, 28, 1)\n",
        "x_test = x_test.reshape(-1,28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFlNHktHBtru"
      },
      "source": [
        "## Train/validation/test data sets\n",
        "\n",
        "\n",
        "*   Training data - used for training the model\n",
        "*   Validation data - used for tuning the hyperparameters and evaluate the models\n",
        "*   Test data - used to test the model after the model has gone through initial vetting by the validation set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhalcO03ZZg3"
      },
      "source": [
        "## Create the model architecture\n",
        "\n",
        "In defining the model we will be using some of these Keras APIs:\n",
        "*   Conv2D() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D/) - create a convolutional layer \n",
        "*   Pooling() [link text](https://keras.io/layers/pooling/) - create a pooling layer \n",
        "*   Dropout() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) - apply drop out "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgTZ47SsZZg4"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # First block\n",
        "    keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    \n",
        "#     # Second block\n",
        "#     keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
        "#     keras.layers.MaxPooling2D(pool_size=2),\n",
        "#     keras.layers.Dropout(0.3),\n",
        "    \n",
        "    # Third block - Fully Connected\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3ZaOZvC9A0b"
      },
      "source": [
        "Draw the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMq_f8PC8zMS"
      },
      "source": [
        "utils.draw_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhxJ5dinZZg8"
      },
      "source": [
        "## Compile the model\n",
        "Configure the learning process with compile() API before training the model. It receives three arguments:\n",
        "\n",
        "*   An optimizer \n",
        "*   A loss function \n",
        "*   A list of metrics \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQUlOa8cZZg9"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtOvh3YVZZg_"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Now let's train the model with fit() API.\n",
        "\n",
        "We use  the [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) API to save the model after every epoch. Set \"save_best_only = True\" to save only when the validation accuracy improves.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTmapAttZZhA"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
        "history = model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=5,\n",
        "         validation_split=0.1,\n",
        "         callbacks=[checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-MGLwZQy05d"
      },
      "source": [
        "## Load Model with the best validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD1tecxUZZhE"
      },
      "source": [
        "# Load the weights with the best validation accuracy\n",
        "model.load_weights('model.weights.best.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RTRkan4yq5H"
      },
      "source": [
        "## Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZtqBqFFy62R"
      },
      "source": [
        "# Evaluate the model on test set\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqwNkZziVZa3"
      },
      "source": [
        "utils.plot_accuracy_and_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJv7XEk10bOv"
      },
      "source": [
        "## Visualize prediction\n",
        "Now let's visualize the prediction using the model you just trained. \n",
        "First we get the predictions with the model from the test data.\n",
        "Then we print out 15 images from the test data set, and set the titles with the prediction (and the groud truth label).\n",
        "Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percent (out of 100) for the predicted label. Note that it can be wrong even when very confident."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQlnbqaw2Qu_"
      },
      "source": [
        "# Plot the first X test images, their predicted label, and the true label\n",
        "# Color correct predictions in blue, incorrect predictions in red\n",
        "predictions = model.predict(x_test)\n",
        "utils.plot_multi_images_prob(predictions, y_test, x_test.reshape(-1, 28, 28), class_names=fashion_mnist_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz6rWiJn7cmB"
      },
      "source": [
        "Lastly, let's view the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZsaJUgm7hRn"
      },
      "source": [
        "# As always - let's convert the probabilities array into classes\n",
        "predicted_classes = utils.label_with_highest_prob(predictions)\n",
        "\n",
        "# Plot the matrix\n",
        "utils.plot_confusion_matrix(y_pred=predicted_classes, y_true=y_test, classes=np.array(fashion_mnist_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AehWdRAVKN5"
      },
      "source": [
        "## Congragulations! \n",
        "You have successfully trained a CNN to classify fashion-MNIST with 90% accuracy."
      ]
    }
  ]
}